{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from requests_html import HTMLSession\n",
    "import csv\n",
    "import datetime\n",
    "import sqlite3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting requests-htmlNote: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 23.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Downloading requests_html-0.10.0-py3-none-any.whl (13 kB)\n",
      "Collecting requests (from requests-html)\n",
      "  Obtaining dependency information for requests from https://files.pythonhosted.org/packages/70/8e/0e2d847013cb52cd35b38c009bb167a1a26b2ce6cd6965bf26b47bc0bf44/requests-2.31.0-py3-none-any.whl.metadata\n",
      "  Downloading requests-2.31.0-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting pyquery (from requests-html)\n",
      "  Downloading pyquery-2.0.0-py3-none-any.whl (22 kB)\n",
      "Collecting fake-useragent (from requests-html)\n",
      "  Obtaining dependency information for fake-useragent from https://files.pythonhosted.org/packages/56/56/f72e9ca4f9cfb966f489c2b8ea04c67fa8d0cfbb62b1651cb9d6aef110a6/fake_useragent-1.3.0-py3-none-any.whl.metadata\n",
      "  Downloading fake_useragent-1.3.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting parse (from requests-html)\n",
      "  Obtaining dependency information for parse from https://files.pythonhosted.org/packages/9c/57/6c51ccd70de3ebcfb0bb5b0eea2ac0ab13c51ab55043a7243faef9eb58ef/parse-1.19.1-py2.py3-none-any.whl.metadata\n",
      "  Downloading parse-1.19.1-py2.py3-none-any.whl.metadata (20 kB)\n",
      "Collecting bs4 (from requests-html)\n",
      "  Downloading bs4-0.0.1.tar.gz (1.1 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting w3lib (from requests-html)\n",
      "  Obtaining dependency information for w3lib from https://files.pythonhosted.org/packages/82/e2/dcf8573d7153194eb673347cea1f9bbdb2a8e61030740fb6f50e4234a00b/w3lib-2.1.2-py3-none-any.whl.metadata\n",
      "  Downloading w3lib-2.1.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting pyppeteer>=0.0.14 (from requests-html)\n",
      "  Downloading pyppeteer-1.0.2-py3-none-any.whl (83 kB)\n",
      "     ---------------------------------------- 0.0/83.4 kB ? eta -:--:--\n",
      "     ---------------------------------------- 83.4/83.4 kB 2.4 MB/s eta 0:00:00\n",
      "Collecting appdirs<2.0.0,>=1.4.3 (from pyppeteer>=0.0.14->requests-html)\n",
      "  Downloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
      "Collecting certifi>=2021 (from pyppeteer>=0.0.14->requests-html)\n",
      "  Obtaining dependency information for certifi>=2021 from https://files.pythonhosted.org/packages/4c/dd/2234eab22353ffc7d94e8d13177aaa050113286e93e7b40eae01fbf7c3d9/certifi-2023.7.22-py3-none-any.whl.metadata\n",
      "  Downloading certifi-2023.7.22-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting importlib-metadata>=1.4 (from pyppeteer>=0.0.14->requests-html)\n",
      "  Obtaining dependency information for importlib-metadata>=1.4 from https://files.pythonhosted.org/packages/cc/37/db7ba97e676af155f5fcb1a35466f446eadc9104e25b83366e8088c9c926/importlib_metadata-6.8.0-py3-none-any.whl.metadata\n",
      "  Downloading importlib_metadata-6.8.0-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting pyee<9.0.0,>=8.1.0 (from pyppeteer>=0.0.14->requests-html)\n",
      "  Downloading pyee-8.2.2-py2.py3-none-any.whl (12 kB)\n",
      "Collecting tqdm<5.0.0,>=4.42.1 (from pyppeteer>=0.0.14->requests-html)\n",
      "  Obtaining dependency information for tqdm<5.0.0,>=4.42.1 from https://files.pythonhosted.org/packages/00/e5/f12a80907d0884e6dff9c16d0c0114d81b8cd07dc3ae54c5e962cc83037e/tqdm-4.66.1-py3-none-any.whl.metadata\n",
      "  Downloading tqdm-4.66.1-py3-none-any.whl.metadata (57 kB)\n",
      "     ---------------------------------------- 0.0/57.6 kB ? eta -:--:--\n",
      "     ---------------------------------------- 57.6/57.6 kB ? eta 0:00:00\n",
      "Collecting urllib3<2.0.0,>=1.25.8 (from pyppeteer>=0.0.14->requests-html)\n",
      "  Obtaining dependency information for urllib3<2.0.0,>=1.25.8 from https://files.pythonhosted.org/packages/48/fe/a5c6cc46e9fe9171d7ecf0f33ee7aae14642f8d74baa7af4d7840f9358be/urllib3-1.26.17-py2.py3-none-any.whl.metadata\n",
      "  Downloading urllib3-1.26.17-py2.py3-none-any.whl.metadata (48 kB)\n",
      "     ---------------------------------------- 0.0/48.7 kB ? eta -:--:--\n",
      "     ---------------------------------------- 48.7/48.7 kB 2.6 MB/s eta 0:00:00\n",
      "Collecting websockets<11.0,>=10.0 (from pyppeteer>=0.0.14->requests-html)\n",
      "  Downloading websockets-10.4-cp311-cp311-win_amd64.whl (101 kB)\n",
      "     ---------------------------------------- 0.0/101.4 kB ? eta -:--:--\n",
      "     -------------------------------------- 101.4/101.4 kB 6.1 MB/s eta 0:00:00\n",
      "Collecting beautifulsoup4 (from bs4->requests-html)\n",
      "  Downloading beautifulsoup4-4.12.2-py3-none-any.whl (142 kB)\n",
      "     ---------------------------------------- 0.0/143.0 kB ? eta -:--:--\n",
      "     -------------------------------------- 143.0/143.0 kB 8.8 MB/s eta 0:00:00\n",
      "Collecting lxml>=2.1 (from pyquery->requests-html)\n",
      "  Obtaining dependency information for lxml>=2.1 from https://files.pythonhosted.org/packages/31/58/e3b3dd6bb2ab7404f1f4992e2d0e6926ed40cef8ce1b3bbefd95877499e1/lxml-4.9.3-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading lxml-4.9.3-cp311-cp311-win_amd64.whl.metadata (3.9 kB)\n",
      "Collecting cssselect>=1.2.0 (from pyquery->requests-html)\n",
      "  Downloading cssselect-1.2.0-py2.py3-none-any.whl (18 kB)\n",
      "Collecting charset-normalizer<4,>=2 (from requests->requests-html)\n",
      "  Obtaining dependency information for charset-normalizer<4,>=2 from https://files.pythonhosted.org/packages/92/5e/50028bbb269986d9bc30270cd46b47ea44a1ca0b3f8da3a8429680d37050/charset_normalizer-3.3.0-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading charset_normalizer-3.3.0-cp311-cp311-win_amd64.whl.metadata (33 kB)\n",
      "Collecting idna<4,>=2.5 (from requests->requests-html)\n",
      "  Downloading idna-3.4-py3-none-any.whl (61 kB)\n",
      "     ---------------------------------------- 0.0/61.5 kB ? eta -:--:--\n",
      "     ---------------------------------------- 61.5/61.5 kB ? eta 0:00:00\n",
      "Collecting zipp>=0.5 (from importlib-metadata>=1.4->pyppeteer>=0.0.14->requests-html)\n",
      "  Obtaining dependency information for zipp>=0.5 from https://files.pythonhosted.org/packages/d9/66/48866fc6b158c81cc2bfecc04c480f105c6040e8b077bc54c634b4a67926/zipp-3.17.0-py3-none-any.whl.metadata\n",
      "  Downloading zipp-3.17.0-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\l\\appdata\\roaming\\python\\python311\\site-packages (from tqdm<5.0.0,>=4.42.1->pyppeteer>=0.0.14->requests-html) (0.4.6)\n",
      "Collecting soupsieve>1.2 (from beautifulsoup4->bs4->requests-html)\n",
      "  Obtaining dependency information for soupsieve>1.2 from https://files.pythonhosted.org/packages/4c/f3/038b302fdfbe3be7da016777069f26ceefe11a681055ea1f7817546508e3/soupsieve-2.5-py3-none-any.whl.metadata\n",
      "  Downloading soupsieve-2.5-py3-none-any.whl.metadata (4.7 kB)\n",
      "Downloading fake_useragent-1.3.0-py3-none-any.whl (15 kB)\n",
      "Downloading parse-1.19.1-py2.py3-none-any.whl (18 kB)\n",
      "Downloading requests-2.31.0-py3-none-any.whl (62 kB)\n",
      "   ---------------------------------------- 0.0/62.6 kB ? eta -:--:--\n",
      "   ---------------------------------------- 62.6/62.6 kB ? eta 0:00:00\n",
      "Downloading w3lib-2.1.2-py3-none-any.whl (21 kB)\n",
      "Downloading certifi-2023.7.22-py3-none-any.whl (158 kB)\n",
      "   ---------------------------------------- 0.0/158.3 kB ? eta -:--:--\n",
      "   ---------------------------------------- 158.3/158.3 kB 9.9 MB/s eta 0:00:00\n",
      "Downloading charset_normalizer-3.3.0-cp311-cp311-win_amd64.whl (97 kB)\n",
      "   ---------------------------------------- 0.0/97.8 kB ? eta -:--:--\n",
      "   ---------------------------------------- 97.8/97.8 kB ? eta 0:00:00\n",
      "Downloading importlib_metadata-6.8.0-py3-none-any.whl (22 kB)\n",
      "Downloading lxml-4.9.3-cp311-cp311-win_amd64.whl (3.8 MB)\n",
      "   ---------------------------------------- 0.0/3.8 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 0.4/3.8 MB 8.7 MB/s eta 0:00:01\n",
      "   ------- -------------------------------- 0.7/3.8 MB 7.3 MB/s eta 0:00:01\n",
      "   -------- ------------------------------- 0.8/3.8 MB 6.3 MB/s eta 0:00:01\n",
      "   -------- ------------------------------- 0.8/3.8 MB 6.3 MB/s eta 0:00:01\n",
      "   ------------ --------------------------- 1.2/3.8 MB 5.1 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 1.6/3.8 MB 6.2 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 1.6/3.8 MB 6.2 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 1.9/3.8 MB 5.2 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 2.4/3.8 MB 5.8 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 2.7/3.8 MB 5.9 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 2.9/3.8 MB 5.8 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 3.2/3.8 MB 5.8 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 3.5/3.8 MB 5.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  3.8/3.8 MB 5.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 3.8/3.8 MB 5.6 MB/s eta 0:00:00\n",
      "Downloading tqdm-4.66.1-py3-none-any.whl (78 kB)\n",
      "   ---------------------------------------- 0.0/78.3 kB ? eta -:--:--\n",
      "   ---------------------------------------- 78.3/78.3 kB 4.5 MB/s eta 0:00:00\n",
      "Downloading urllib3-1.26.17-py2.py3-none-any.whl (143 kB)\n",
      "   ---------------------------------------- 0.0/143.4 kB ? eta -:--:--\n",
      "   ---------------------------------------- 143.4/143.4 kB 8.3 MB/s eta 0:00:00\n",
      "Downloading soupsieve-2.5-py3-none-any.whl (36 kB)\n",
      "Downloading zipp-3.17.0-py3-none-any.whl (7.4 kB)\n",
      "Building wheels for collected packages: bs4\n",
      "  Building wheel for bs4 (pyproject.toml): started\n",
      "  Building wheel for bs4 (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for bs4: filename=bs4-0.0.1-py3-none-any.whl size=1265 sha256=ce6cb463296bb6ca3303ec4b956482eaebe6422b065bbdc76689ac058585e037\n",
      "  Stored in directory: c:\\users\\l\\appdata\\local\\pip\\cache\\wheels\\d4\\c8\\5b\\b5be9c20e5e4503d04a6eac8a3cd5c2393505c29f02bea0960\n",
      "Successfully built bs4\n",
      "Installing collected packages: pyee, parse, fake-useragent, appdirs, zipp, websockets, w3lib, urllib3, tqdm, soupsieve, lxml, idna, cssselect, charset-normalizer, certifi, requests, pyquery, importlib-metadata, beautifulsoup4, pyppeteer, bs4, requests-html\n",
      "Successfully installed appdirs-1.4.4 beautifulsoup4-4.12.2 bs4-0.0.1 certifi-2023.7.22 charset-normalizer-3.3.0 cssselect-1.2.0 fake-useragent-1.3.0 idna-3.4 importlib-metadata-6.8.0 lxml-4.9.3 parse-1.19.1 pyee-8.2.2 pyppeteer-1.0.2 pyquery-2.0.0 requests-2.31.0 requests-html-0.10.0 soupsieve-2.5 tqdm-4.66.1 urllib3-1.26.17 w3lib-2.1.2 websockets-10.4 zipp-3.17.0\n"
     ]
    }
   ],
   "source": [
    "pip install requests-html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3325246516.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[1], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    install pip\u001b[0m\n\u001b[1;37m            ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "install pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sqlite3.connect('amztracker.db')\n",
    "c = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'asins.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\l\\Desktop\\programming\\machine learning\\amazon_price_analyzer.ipynb Cell 5\u001b[0m line \u001b[0;36m5\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/l/Desktop/programming/machine%20learning/amazon_price_analyzer.ipynb#X11sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m asins \u001b[39m=\u001b[39m []\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/l/Desktop/programming/machine%20learning/amazon_price_analyzer.ipynb#X11sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m#read csv to list\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/l/Desktop/programming/machine%20learning/amazon_price_analyzer.ipynb#X11sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39;49m(\u001b[39m'\u001b[39;49m\u001b[39masins.csv\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mr\u001b[39;49m\u001b[39m'\u001b[39;49m) \u001b[39mas\u001b[39;00m f:\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/l/Desktop/programming/machine%20learning/amazon_price_analyzer.ipynb#X11sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     csv_reader \u001b[39m=\u001b[39m csv\u001b[39m.\u001b[39mreader(f)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/l/Desktop/programming/machine%20learning/amazon_price_analyzer.ipynb#X11sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     \u001b[39mfor\u001b[39;00m row \u001b[39min\u001b[39;00m csv_reader:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\interactiveshell.py:286\u001b[0m, in \u001b[0;36m_modified_open\u001b[1;34m(file, *args, **kwargs)\u001b[0m\n\u001b[0;32m    279\u001b[0m \u001b[39mif\u001b[39;00m file \u001b[39min\u001b[39;00m {\u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m}:\n\u001b[0;32m    280\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    281\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mIPython won\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt let you open fd=\u001b[39m\u001b[39m{\u001b[39;00mfile\u001b[39m}\u001b[39;00m\u001b[39m by default \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    282\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    283\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39myou can use builtins\u001b[39m\u001b[39m'\u001b[39m\u001b[39m open.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    284\u001b[0m     )\n\u001b[1;32m--> 286\u001b[0m \u001b[39mreturn\u001b[39;00m io_open(file, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'asins.csv'"
     ]
    }
   ],
   "source": [
    "s = HTMLSession()\n",
    "asins = []\n",
    "\n",
    "#read csv to list\n",
    "with open('asins.csv', 'r') as f:\n",
    "    csv_reader = csv.reader(f)\n",
    "    for row in csv_reader:\n",
    "        asins.append(row[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Committed new entries to database\n"
     ]
    }
   ],
   "source": [
    "for asin in asins:\n",
    "    r = s.get(f'https://www.amazon.co.uk/dp/{asin}')\n",
    "    r.html.render(sleep=1)\n",
    "    try: \n",
    "        price = r.html.find('#price_inside_buybox')[0].text.replace('£','').replace(',','').strip()\n",
    "    except:\n",
    "        price = r.html.find('#priceblock_ourprice')[0].text.replace('£','').replace(',','').strip()\n",
    "    title = r.html.find('#productTitle')[0].text.strip()\n",
    "    asin = asin\n",
    "    date = datetime.datetime.today()\n",
    "    c.execute('''INSERT INTO prices VALUES(?,?,?,?)''', (date, asin, price, title))\n",
    "    print(f'Added data for {asin}, {price}')\n",
    "\n",
    "conn.commit()\n",
    "print('Committed new entries to database')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
